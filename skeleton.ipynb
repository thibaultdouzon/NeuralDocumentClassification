{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clemsage/NeuralDocumentClassification/blob/master/skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j5UeZiGlvNoH"
      },
      "source": [
        "# Setting up the computing environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n52k6VoU1brz"
      },
      "source": [
        "## Install and import PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zZVpUWUluZbV"
      },
      "source": [
        "Select \"GPU\" in the Accelerator drop-down on Notebook Settings through the Edit menu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "cellView": "both",
        "colab": {},
        "colab_type": "code",
        "id": "8XYfp8LNcRD3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.1+cu121\n"
          ]
        }
      ],
      "source": [
        "# %pip install torch torchvision numpy matplotlib Pillow datasets\n",
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nkd4MHFQv0jS"
      },
      "source": [
        "## Confirm PyTorch can see the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nbotnVwUpWBa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IRPpWCXA05ka"
      },
      "source": [
        "## Additional information about hardware"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k8XAtu4u1mXZ"
      },
      "source": [
        "For CPU information and RAM, run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4Mr3-8s-1jPB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 2\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 1\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 2\n",
            "initial apicid\t: 2\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 3\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 1\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 3\n",
            "initial apicid\t: 3\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 4\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 2\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 4\n",
            "initial apicid\t: 4\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 5\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 2\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 5\n",
            "initial apicid\t: 5\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 6\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 3\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 6\n",
            "initial apicid\t: 6\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 7\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 3\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 7\n",
            "initial apicid\t: 7\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 8\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 4\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 8\n",
            "initial apicid\t: 8\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 9\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 4\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 9\n",
            "initial apicid\t: 9\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 10\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 5\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 10\n",
            "initial apicid\t: 10\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 11\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 5\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 11\n",
            "initial apicid\t: 11\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 12\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 6\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 12\n",
            "initial apicid\t: 12\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 13\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 6\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 13\n",
            "initial apicid\t: 13\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 14\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 7\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 14\n",
            "initial apicid\t: 14\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 15\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 7\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 15\n",
            "initial apicid\t: 15\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 16\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 8\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 16\n",
            "initial apicid\t: 16\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 17\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 8\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 17\n",
            "initial apicid\t: 17\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 18\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 9\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 18\n",
            "initial apicid\t: 18\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 19\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 154\n",
            "model name\t: 12th Gen Intel(R) Core(TM) i7-12800H\n",
            "stepping\t: 3\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2803.212\n",
            "cache size\t: 24576 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 20\n",
            "core id\t\t: 9\n",
            "cpu cores\t: 10\n",
            "apicid\t\t: 19\n",
            "initial apicid\t: 19\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 21\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves umip gfni vaes vpclmulqdq rdpid fsrm md_clear flush_l1d arch_capabilities\n",
            "bugs\t\t: spectre_v1 spectre_v2 spec_store_bypass swapgs retbleed eibrs_pbrsb\n",
            "bogomips\t: 5606.42\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MemTotal:       32708976 kB\n",
            "MemFree:        16791772 kB\n",
            "MemAvailable:   28810364 kB\n",
            "Buffers:          218656 kB\n",
            "Cached:         11807216 kB\n",
            "SwapCached:            0 kB\n",
            "Active:           907692 kB\n",
            "Inactive:       14107624 kB\n",
            "Active(anon):       2352 kB\n",
            "Inactive(anon):  2991704 kB\n",
            "Active(file):     905340 kB\n",
            "Inactive(file): 11115920 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:       8388608 kB\n",
            "SwapFree:        8388608 kB\n",
            "Dirty:              8424 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:       2949352 kB\n",
            "Mapped:           774036 kB\n",
            "Shmem:              4644 kB\n",
            "KReclaimable:     457268 kB\n",
            "Slab:             533240 kB\n",
            "SReclaimable:     457268 kB\n",
            "SUnreclaim:        75972 kB\n",
            "KernelStack:       11408 kB\n",
            "PageTables:        37524 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:    24743096 kB\n",
            "Committed_AS:    5517696 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:       33812 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             6912 kB\n",
            "AnonHugePages:    909312 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:       19456 kB\n",
            "DirectMap2M:     5060608 kB\n",
            "DirectMap1G:    36700160 kB\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/cpuinfo\n",
        "!cat /proc/meminfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ic-CaNISucO-"
      },
      "source": [
        "## Other useful package imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gevJulhruagf"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "from collections import Counter\n",
        "from dataclasses import dataclass\n",
        "from os import path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0kDf1Kmntpwo"
      },
      "source": [
        "# Working on the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pQe3wu4U5kOt"
      },
      "source": [
        "The dataset is a subset of the [RVL-CDIP dataset](https://www.cs.cmu.edu/~aharley/rvl-cdip/). See [Harley et al.](http://scs.ryerson.ca/~aharley/icdar15/harley_convnet_icdar15.pdf) and [Asim et al.](https://www.dfki.de/fileadmin/user_upload/import/10637_Asim_Document_Image_Classification.pdf) papers for recent works on this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jH2SxwR_1Rpu"
      },
      "source": [
        "## Information about the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lxvfM7Wn_YUQ"
      },
      "source": [
        "This project only considers the following 5 classes among the 16 classes of the original dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "cellView": "both",
        "colab": {},
        "colab_type": "code",
        "id": "lGLInZca1Pbg"
      },
      "outputs": [],
      "source": [
        "class_names = [\"email\", \"form\", \"handwritten\", \"invoice\", \"advertisement\"]\n",
        "NUM_CLASSES = len(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XgN4fpA0uO8n"
      },
      "source": [
        "## Import the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AVnJr5tzswrq"
      },
      "source": [
        "First, clone or pull the GitHub repository of the project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ST3fUpSmqncY"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"NeuralDocumentClassification\"):\n",
        "    !git clone https://github.com/thibaultdouzon/NeuralDocumentClassification.git\n",
        "else:\n",
        "    !git -C NeuralDocumentClassification pull\n",
        "sys.path.append(\"NeuralDocumentClassification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9zWbX_GYypxH"
      },
      "source": [
        "Download the train, test and validation dataset assignments from this [Google Drive](https://drive.google.com/drive/folders/1Pkd6sUkDGBUymWKK93abZx1MQiWmzFgP):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pQJ8Kqy3sv_v"
      },
      "outputs": [],
      "source": [
        "from src import download_dataset\n",
        "\n",
        "importlib.reload(download_dataset)\n",
        "dataset_path = \"dataset\"\n",
        "\n",
        "download_dataset.download_and_extract(\"all\", dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VYoAg4lOau3h"
      },
      "source": [
        "Each dataset file is a binary dump that can be loaded with the [Pickle](https://docs.python.org/3.11/library/pickle.html) module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "a4G-8jVJauWC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_dataset contains 5000 documents\n",
            "test_dataset contains 1000 documents\n",
            "validation_dataset contains 500 documents\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "dict_keys(['id', 'image', 'label', 'words', 'boxes'])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(path.join(dataset_path, \"train.pkl\"), \"rb\") as f:\n",
        "    train_dataset = pickle.load(f)\n",
        "\n",
        "with open(path.join(dataset_path, \"test.pkl\"), \"rb\") as f:\n",
        "    test_dataset = pickle.load(f)\n",
        "\n",
        "with open(path.join(dataset_path, \"validation.pkl\"), \"rb\") as f:\n",
        "    validation_dataset = pickle.load(f)\n",
        "\n",
        "\n",
        "for split_name, split_dataset in zip(\n",
        "    [\"train\", \"test\", \"validation\"], [train_dataset, test_dataset, validation_dataset]\n",
        "):\n",
        "    print(f\"{split_name}_dataset contains {len(split_dataset)} documents\")\n",
        "train_dataset[0].keys()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each `dataset` object is a `list` containing multiple document information. A document is a `dict` with the following structure:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"id\": \"Unique document identifier\",\n",
        "    \"image\": \"A PIL.Image object containing the document's image\",\n",
        "    \"label\": \"A number between in [0 .. 4] representing the class of the document\",\n",
        "    \"words\": \"A list of words extracted from the image with an OCR\",\n",
        "    \"boxes\": \"A list of tuples of numbers providing the position of each word in the document\"\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1NRF5WhuiW3S"
      },
      "source": [
        "List the image files of the training and test dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "93EnbGGRid77"
      },
      "source": [
        "Print 5 image from the training dataset using [matplotlib](https://matplotlib.org/stable/tutorials/images.html) `plt` module:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Lw4UmzI2_FV_"
      },
      "outputs": [],
      "source": [
        "### Insert your code here ###\n",
        "# See the expected solution by clicking on the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "xlg7AAuoiAPU"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "for document in train_dataset[:5]:\n",
        "    print(class_names[document[\"label\"]])\n",
        "    plt.imshow(document[\"image\"].convert(\"RGB\"))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pTo64W_682WR"
      },
      "source": [
        "# Creating Pytorch datasets and dataloaders for Computer Vision task\n",
        "\n",
        "The first goal of this section is to create `torch.utils.data.Dataset` for the classification task using only the image of the document.\n",
        "\n",
        "We will define a class inheriting [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) called `DocumentImageDataset`.\n",
        "\n",
        "It should be able to create an instance of `DocumentImageDataset` using our previously loaded datasets.\n",
        "For simplification, all images should be formatted to black and white (remove the color channel), and resized to a fixed (512, 512) size. Use [`torchvision.transforms.v2.functional`](https://pytorch.org/vision/main/transforms.html#v2-api-reference-recommended) module to convert a `PIL.Image` to a `torch.Tensor` and perform the simplifications.\n",
        "\n",
        "Upon iteration, it should return an `ImageSample` object defined as follows:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms.v2.functional as F\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ImageSample:\n",
        "    image: torch.Tensor  # shape: (H, W)\n",
        "    label: int  # 0 â‰¤ label < NUM_CLASSES\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"Some assertions to check the validity of the data\"\n",
        "        assert self.image.shape == (\n",
        "            512,\n",
        "            512,\n",
        "        ), f\"Expected shape (512, 512), got {self.image.shape}\"\n",
        "        assert torch.all(self.image <= 1.0) and torch.all(\n",
        "            self.image >= 0.0\n",
        "        ), \"Expected each pixel of image in range [0.0, 1.0]\"\n",
        "        assert self.label in range(\n",
        "            NUM_CLASSES\n",
        "        ), f\"Expected label in range [0 .. {NUM_CLASSES-1}], got {self.label}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "e7QYsgFr88jO"
      },
      "outputs": [],
      "source": [
        "## Fill the methods of the class DocumentImageDataset\n",
        "\n",
        "\n",
        "class DocumentImageDataset(data.Dataset):\n",
        "    def __init__(self, dataset: list[dict]):\n",
        "        self.dataset = dataset\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"This method returns the length of the dataset\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __getitem__(self, idx: int) -> ImageSample:\n",
        "        \"\"\"This method returns the idx-th sample of the dataset\n",
        "        If idx is out of bounds, it should raise an IndexError\"\"\"\n",
        "\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "\n",
        "class DocumentImageDataset(data.Dataset):\n",
        "    def __init__(self, dataset: list[dict]):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"This method returns the length of the dataset\"\"\"\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> ImageSample:\n",
        "        \"\"\"This method returns the idx-th sample of the dataset\n",
        "        If idx is out of bounds, it should raise an IndexError\"\"\"\n",
        "\n",
        "        return ImageSample(\n",
        "            image=F.to_dtype(\n",
        "                F.to_image(F.resize(self.dataset[idx][\"image\"], size=[512, 512])),\n",
        "                dtype=torch.float32,\n",
        "                scale=True,\n",
        "            )[0],\n",
        "            label=self.dataset[idx][\"label\"],\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If your implementation is correct, you should be able to create an instance of `DocumentImageDataset` and get its 0th element without error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ImageSample(image=tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.]]), label=3)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_dataset = DocumentImageDataset(validation_dataset)\n",
        "image_dataset[0]  # no error here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The final goal of this section is to implement a [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) that wraps the `DocumentImageDataset` and handles useful tasks like shuffling and batching.\n",
        "\n",
        "No need to create a new class, we simply need to implement the `collate_fn` that takes a list of `ImageSample` and should return an `ImageBatch`.\n",
        "\n",
        "\n",
        "hint: Use `torch.tensor` and `torch.stack` to respectively convert a python list to a `torch.Tensor` and stack multiple tensors together into a new one along a new dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ImageBatch:\n",
        "    images: torch.Tensor\n",
        "    labels: torch.Tensor\n",
        "\n",
        "    def __post_init__(self):\n",
        "        assert self.images.shape[0] == self.labels.shape[0]\n",
        "        assert self.images.shape[1:] == (512, 512)\n",
        "        assert len(self.images.shape) == 3\n",
        "        assert len(self.labels.shape) == 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(batch: list[ImageSample]) -> ImageBatch:\n",
        "    \"\"\"This function should return a batch of samples as an ImageBatch object\"\"\"\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "\n",
        "def collate_fn(batch: list[ImageSample]) -> ImageBatch:\n",
        "    \"\"\"This function should return a batch of samples as an ImageBatch object\"\"\"\n",
        "    return ImageBatch(\n",
        "        images=torch.stack(\n",
        "            [sample.image for sample in batch], dim=0\n",
        "        ),  # shape: (B, H, W)\n",
        "        labels=torch.tensor([sample.label for sample in batch]),  # shape: (B,)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If your implementation is correct, you should be able to create a dataloader with a batch size and retrieve the first batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ImageBatch(images=tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         ...,\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
              "\n",
              "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         ...,\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
              "\n",
              "        [[0.3922, 0.9098, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [0.2549, 0.8902, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [0.2549, 0.8902, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         ...,\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [0.8431, 0.7961, 0.7882,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [0.1725, 0.1176, 0.1098,  ..., 1.0000, 1.0000, 1.0000]],\n",
              "\n",
              "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         ...,\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
              "\n",
              "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         ...,\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
              "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]]), labels=tensor([1, 1, 2, 3, 3]))"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataloader = data.DataLoader(\n",
        "    image_dataset, batch_size=5, collate_fn=collate_fn, shuffle=True\n",
        ")\n",
        "next(iter(dataloader))  # no error here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_1Eq6TC2wicn"
      },
      "source": [
        "## Explore the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MWJshtOvIpfo"
      },
      "source": [
        "Get image shape and label for one element of the training dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NQ7bN2jc0rNK"
      },
      "outputs": [],
      "source": [
        "for image, label in labeled_train_ds.take(1):\n",
        "    print(\"Image shape (height, width, depth):\", image.numpy().shape)\n",
        "    print(\"Label:\", class_names[label.numpy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XVm4YLGH1Y9_"
      },
      "source": [
        "Plot 3 random training images of each class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qwsI8QQkEUMV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30, 60))\n",
        "n_images_per_class = 3\n",
        "\n",
        "for image, label in labeled_train_ds:\n",
        "    break  # Sample images and labels for each class\n",
        "\n",
        "for class_idx, class_name in enumerate(class_names):\n",
        "    for i in range(n_images_per_class):\n",
        "        plt.subplot(\n",
        "            NUM_CLASSES, n_images_per_class, class_idx * n_images_per_class + i + 1\n",
        "        )\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        # plt.imshow(...)\n",
        "        # plt.xlabel(...)\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "ET7vBNIU15pQ"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "plt.figure(figsize=(30, 60))\n",
        "n_images_per_class = 3\n",
        "images = {class_name: [] for class_name in class_names}\n",
        "\n",
        "for image, label in labeled_train_ds:\n",
        "    image = image.numpy()\n",
        "    label = label.numpy()\n",
        "\n",
        "    if len(images[class_names[label]]) < n_images_per_class:\n",
        "        images[class_names[label]].append(image)\n",
        "\n",
        "    if all(\n",
        "        [len(images[class_name]) == n_images_per_class for class_name in class_names]\n",
        "    ):\n",
        "        break\n",
        "\n",
        "for class_idx, class_name in enumerate(class_names):\n",
        "    for i in range(n_images_per_class):\n",
        "        plt.subplot(\n",
        "            NUM_CLASSES, n_images_per_class, class_idx * n_images_per_class + i + 1\n",
        "        )\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(np.squeeze(images[class_name][i]), cmap=\"gray\")\n",
        "        plt.xlabel(class_name)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gTiy3OjTzPm7"
      },
      "source": [
        "Print the class distribution in the training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9XaIjc79II9E"
      },
      "outputs": [],
      "source": [
        "cnt_class = Counter()\n",
        "for file_path in dataset[\"training\"]:\n",
        "    label = labels_idx.lookup(tf.constant(file_path))\n",
        "    # Update the counter with the label value\n",
        "\n",
        "# Print the class counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "MjyrGh3szWs5"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "cnt_class = Counter()\n",
        "for file_path in dataset[\"training\"]:\n",
        "    label = labels_idx.lookup(tf.constant(file_path))\n",
        "    cnt_class.update([class_names[label.numpy()]])\n",
        "\n",
        "for key, val in cnt_class.most_common():\n",
        "    print(\"%s: %d\" % (key, val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vECBpU3JCxyt"
      },
      "source": [
        "## Prepare training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kxJ3RtsuK3nu"
      },
      "source": [
        "Use a temporary folder for caching elements of the dataset in order to speed up training and testing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Nx5JO952KSqj"
      },
      "outputs": [],
      "source": [
        "temp_folder = \"/tmp/%dx%dx1\" % (IMG_HEIGHT, IMG_WIDTH)\n",
        "labeled_train_ds = labeled_train_ds.cache(temp_folder)\n",
        "labeled_test_ds = labeled_test_ds.cache(temp_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aSD1NL7g3kSt"
      },
      "source": [
        "Shuffle the documents within each subset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pYalPpQi3oeh"
      },
      "outputs": [],
      "source": [
        "labeled_train_ds = labeled_train_ds.shuffle(2048)\n",
        "labeled_test_ds = labeled_test_ds.shuffle(2048)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eOXl8eGcJP_J"
      },
      "source": [
        "Batch documents within each subset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ejTxwX3KJ4Gm"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "labeled_train_ds = labeled_train_ds.batch(batch_size)\n",
        "labeled_test_ds = labeled_test_ds.batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-18lHiag4uiS"
      },
      "source": [
        "Prefetch the subsets in the background while the model is computing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Je7kuYFh4y_2"
      },
      "outputs": [],
      "source": [
        "labeled_train_ds = labeled_train_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "labeled_test_ds = labeled_test_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9oQZqkwA5mRU"
      },
      "source": [
        "# Visual classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JcRvGBPJCPAI"
      },
      "source": [
        "## Fully connected neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hmD69yYP8Z7X"
      },
      "source": [
        "### Set up the layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ooKloCG47hA4"
      },
      "source": [
        "Build a neural network composed of one fully connected (aka dense) hidden layer with 128 [ReLu](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) units and one output softmax layer.\n",
        "\n",
        "Each image must be reshaped to a 1 dimensional vector before being fed to the hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YCIzEefKKKNK"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        # Insert your layers here, see the following documentation:\n",
        "        # https://www.tensorflow.org/tutorials/quickstart/beginner\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "HYxVCSLQ5tmk"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6JjOGshU8ftf"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pHGhRxVD8wl-"
      },
      "source": [
        "Compile the model by providing the optimizer, the loss function you want to minimize and the metrics to monitor during training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Lhan11blCaW7"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",  # https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
        "    loss=\"sparse_categorical_crossentropy\",  # Loss used for multi-class classification with integer labels\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy\n",
        "    metrics=[\n",
        "        \"sparse_categorical_accuracy\"\n",
        "    ],  # https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qsnjxEZ8gJ1I"
      },
      "source": [
        "Print a summary of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8UUZ51MmgUhL"
      },
      "outputs": [],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-GFuLNGh9U5w"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ut4NKowCE8Hz"
      },
      "source": [
        "Fit the model on the training set for 20 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vO1F5yxIMgY-"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20\n",
        "# model.fit(...)  # https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "4nT6h3y_9XFo"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "EPOCHS = 10\n",
        "model.fit(labeled_train_ds, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nfLk6pw2M08a"
      },
      "source": [
        "### Evaluation on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HNIV9G61P3SB"
      },
      "source": [
        "Get the values of the loss and accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vGOSP20hqZ68"
      },
      "outputs": [],
      "source": [
        "# model.evaluate(..., verbose=2) # https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "wq93ddH0NDpS"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "model.evaluate(labeled_test_ds, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x_gKCPtWVg3M"
      },
      "source": [
        "Are these values different from their training counterparts ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XXHM8y9kRW5V"
      },
      "source": [
        "### Prediction on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5xHWavjURp-t"
      },
      "source": [
        "Implement a function that gathers the model predictions and the ground truth labels for a random batch of a given dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hq68PQDJsbXh"
      },
      "outputs": [],
      "source": [
        "def predict_random_batch(model, dataset):\n",
        "    \"\"\"\n",
        "    Sample a random batch of the dataset and return the images of this batch\n",
        "    as well as its labels and the predicted classes of a given model\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : tf.keras.Model\n",
        "    dataset: tf.data.Dataset\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    images: np.ndarray or EagerTensor\n",
        "    labels: list of str\n",
        "    predicted_classes: list of str\n",
        "    \"\"\"\n",
        "    images, labels = next(iter(dataset))\n",
        "\n",
        "    # get label names for the sampled batch\n",
        "\n",
        "    # make predictions\n",
        "    predicted_classes = None\n",
        "\n",
        "    return images, labels, predicted_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "xX0MIEONRkp7"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "def predict_random_batch(model, dataset):\n",
        "    \"\"\"\n",
        "    Sample a random batch of the dataset and return the images of this batch\n",
        "    as well as its labels and the predicted classes of a given model\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : tf.keras.Model\n",
        "    dataset: tf.data.Dataset\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    images: np.ndarray or EagerTensor\n",
        "    labels: list of str\n",
        "    predicted_classes: list of str\n",
        "    \"\"\"\n",
        "    images, labels = next(iter(dataset))\n",
        "\n",
        "    # get label names for the sampled batch\n",
        "    labels = [class_names[i] for i in labels]\n",
        "\n",
        "    # make predictions\n",
        "    predictions = model.predict(images)\n",
        "    predicted_classes_idx = np.argmax(predictions, axis=1)\n",
        "    predicted_classes = [class_names[i] for i in predicted_classes_idx]\n",
        "\n",
        "    return images, labels, predicted_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uyZFGQLLVFeC"
      },
      "source": [
        "Plot the first 9 images of this batch, give their labels and predicted classes in the legend:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wrgwVDo4VFG7"
      },
      "outputs": [],
      "source": [
        "def plot_images_predictions_and_labels(images, labels, predicted_classes):\n",
        "    plt.figure(figsize=(30, 40))\n",
        "\n",
        "    for im_idx in range(9):\n",
        "        plt.subplot(3, 3, im_idx + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(np.squeeze(images[im_idx]), cmap=\"gray\")\n",
        "        plt.xlabel(\"label: %s\\npred: %s\" % (labels[im_idx], predicted_classes[im_idx]))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "result = predict_random_batch(model, labeled_test_ds)\n",
        "plot_images_predictions_and_labels(*result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "monzP4ZVVkGr"
      },
      "source": [
        "### Under the Hood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "61YBF5sLfsrZ"
      },
      "source": [
        "Implement an ReLu dense layer by creating its weights and biases and giving the transformation from inputs to outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8_-Q8GwoChTv"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/guide/keras/custom_layers_and_models#the_layer_class\n",
        "class MyDenseLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyDenseLayer, self).__init__()\n",
        "        self.w = self.add_weight(\n",
        "            shape=None,  ## Insert the shape of the weight matrix here\n",
        "            initializer=\"glorot_uniform\",  # Default initializer for weights of a tf.keras.layers.Dense layer\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "        self.b = self.add_weight(\n",
        "            shape=None,  ## Insert the shape of the bias vector here\n",
        "            initializer=\"zeros\",  # Default initializer for biases of a tf.keras.layers.Dense layer\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        outputs = None\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "5HWRDQkPfBam"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# https://www.tensorflow.org/guide/keras/custom_layers_and_models#the_layer_class\n",
        "class MyDenseLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyDenseLayer, self).__init__()\n",
        "        self.w = self.add_weight(\n",
        "            shape=(input_dim, units),\n",
        "            initializer=\"glorot_uniform\",  # Default initializer for weights of a tf.keras.layers.Dense layer\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "        self.b = self.add_weight(\n",
        "            shape=(units,),\n",
        "            initializer=\"zeros\",  # Default initializer for biases of a tf.keras.layers.Dense layer\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.keras.activations.relu(tf.matmul(inputs, self.w) + self.b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VyPOuiP_5ZGv"
      },
      "source": [
        "Using your custom hidden layer, set up again the layers of the model defined previously:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8fK9p35mD9eI"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "        ## Insert your custom hidden layer here\n",
        "        tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "CBd68qImh1zH"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "        MyDenseLayer(128, IMG_HEIGHT * IMG_WIDTH),\n",
        "        tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eVgtyKeNhXJR"
      },
      "source": [
        "Lower-level implementation of the model compile step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-4IEM4Rhg4ji"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images)\n",
        "        loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VxMO3ZB7ic0-"
      },
      "source": [
        "Lower-level implementation of the model fit step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Mo77GEbdifjm"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    for images, labels in labeled_train_ds:\n",
        "        train_step(images, labels)\n",
        "        template = \"Epoch {}, Loss: {}, Accuracy: {}\"\n",
        "        print(\n",
        "            template.format(\n",
        "                epoch + 1, train_loss.result(), train_accuracy.result() * 100\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LnMkYilGngXs"
      },
      "source": [
        "## Convolutional Neural Networks (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Kaz6G-cbotNS"
      },
      "source": [
        "### Training from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gNifb_-ImoL1"
      },
      "source": [
        "Create and compile a model alterning convolution and max pooling layers. You can add some fully connected layers between the last locally connected layer and the output layer. Start with a shallow network (4 or 5 convolution layers) and progressively move to deeper architectures: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5VSo8vjiGOUc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        # Alterning Conv2D and MaxPooling2D layers\n",
        "        # Some dense hidden layer(s)\n",
        "        Dense(NUM_CLASSES, activation=\"softmax\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "R-fLDDzLmjMH"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "shallow_model = tf.keras.Sequential(\n",
        "    [\n",
        "        Conv2D(\n",
        "            16,\n",
        "            3,\n",
        "            padding=\"same\",\n",
        "            activation=\"relu\",\n",
        "            input_shape=(IMG_HEIGHT, IMG_WIDTH, 1),\n",
        "        ),\n",
        "        MaxPooling2D(4),\n",
        "        Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(4),\n",
        "        Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(4),\n",
        "        Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(4),\n",
        "        Flatten(),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        Dense(NUM_CLASSES, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "deep_model = tf.keras.Sequential(\n",
        "    [\n",
        "        Conv2D(\n",
        "            16,\n",
        "            3,\n",
        "            padding=\"same\",\n",
        "            activation=\"relu\",\n",
        "            input_shape=(IMG_HEIGHT, IMG_WIDTH, 1),\n",
        "        ),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(256, 3, padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(256, 3, padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(256, 3, padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(256, 3, padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(),\n",
        "        Flatten(),\n",
        "        Dense(256, activation=\"relu\"),\n",
        "        Dense(NUM_CLASSES, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model_with_strides = tf.keras.Sequential(\n",
        "    [\n",
        "        Conv2D(\n",
        "            16,\n",
        "            3,\n",
        "            padding=\"same\",\n",
        "            activation=\"relu\",\n",
        "            input_shape=(IMG_HEIGHT, IMG_WIDTH, 1),\n",
        "        ),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(64, 3, padding=\"same\", activation=\"relu\", strides=2),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(128, 3, padding=\"same\", activation=\"relu\", strides=2),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(128, 3, padding=\"same\", activation=\"relu\", strides=2),\n",
        "        MaxPooling2D(),\n",
        "        Flatten(),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        Dense(NUM_CLASSES, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "model = deep_model\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FVzSjxP0qP4D"
      },
      "source": [
        "Fit the CNN on the training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3jWd_WMpqPi8"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "model.fit(labeled_train_ds, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9mGpqBc7rnFv"
      },
      "source": [
        "Evaluate the trained model on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tSmadMoVrmnf"
      },
      "outputs": [],
      "source": [
        "model.evaluate(labeled_test_ds, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xK3wwRUPOBEs"
      },
      "source": [
        "You should reach test accuracy greater than 0.99 !\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7S7XNOyD3pRI"
      },
      "source": [
        "Plot images, predictions and labels for some test documents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FZ4le3PQuWYo"
      },
      "outputs": [],
      "source": [
        "plot_images_predictions_and_labels(*predict_random_batch(model, labeled_test_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ArNeT3D1nINR"
      },
      "source": [
        "### Transfer Learning with pre-trained models "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PS-BCUYYRr_I"
      },
      "source": [
        "The objective is to leverage the knowledge learnt by a pre-trained image classifier. See [TensorFlow Hub](https://tfhub.dev/) to browse available state-of-the art models such as [Inception V3](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf) or [MobileNet V2](https://arxiv.org/pdf/1801.04381.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Q7LRLglIQMY"
      },
      "source": [
        "Choose a pre-trained model for extracting high level feature vectors of document images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5F0WHgxTJX0S"
      },
      "outputs": [],
      "source": [
        "extractor_model = \"inception_v3\"\n",
        "if extractor_model == \"inception_v3\":\n",
        "    feature_extraction_url = (\n",
        "        \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
        "    )\n",
        "    IMG_HEIGHT, IMG_WIDTH = None, None  ## Insert expected input image shape here\n",
        "elif extractor_model == \"mobilenet_v2\":\n",
        "    feature_extraction_url = (\n",
        "        \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
        "    )\n",
        "    IMG_HEIGHT, IMG_WIDTH = None, None  ## Insert expected input image shape here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "ho18UyThppL6"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "extractor_model = \"inception_v3\"\n",
        "if extractor_model == \"inception_v3\":\n",
        "    feature_extraction_url = (\n",
        "        \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
        "    )\n",
        "    IMG_HEIGHT, IMG_WIDTH = 299, 299\n",
        "elif extractor_model == \"mobilenet_v2\":\n",
        "    feature_extraction_url = (\n",
        "        \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
        "    )\n",
        "    IMG_HEIGHT, IMG_WIDTH = 224, 224"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WS2LwuZGPfg_"
      },
      "source": [
        "Reshape images to the format expected by the chosen model, i.e. IMG_HEIGHT x IMG_WIDTH x 3 (RGB) and recreate training dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "D51vnWCPPunJ"
      },
      "outputs": [],
      "source": [
        "def decode_img(img):\n",
        "    # convert the compressed string to a uint8 tensor\n",
        "    img = tf.io.decode_png(img, channels=1)\n",
        "    # convert to floats in the [0,1] range\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    # resize the image to the desired size\n",
        "    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
        "    # convert to RGB color scale\n",
        "    img = tf.concat([img for _ in range(3)], axis=-1)  # R = G = B\n",
        "    return img\n",
        "\n",
        "\n",
        "def process_path(file_path):\n",
        "    label = labels_idx.lookup(file_path)\n",
        "\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = decode_img(img)\n",
        "    return img, label\n",
        "\n",
        "\n",
        "labeled_train_ds = list_train_ds.map(\n",
        "    process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        ")\n",
        "labeled_train_ds = labeled_train_ds.cache(\"/tmp/%dx%dx3\" % (IMG_HEIGHT, IMG_WIDTH))\n",
        "labeled_train_ds = labeled_train_ds.shuffle(2048).batch(batch_size)\n",
        "labeled_train_ds = labeled_train_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1WXZOzEvnINO"
      },
      "source": [
        "Construct our own image classifier by retrieving and freezing the hidden layers of the pre-trained model: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JRq-5IVoMQFD"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "aDMImRlEnINF"
      },
      "outputs": [],
      "source": [
        "# @title\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m0fx9gcSRaKf"
      },
      "source": [
        "Train this new model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gecTChcfRc-K"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "model.fit(labeled_train_ds, epochs=EPOCHS)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "j5UeZiGlvNoH",
        "n52k6VoU1brz",
        "nkd4MHFQv0jS",
        "IRPpWCXA05ka",
        "ic-CaNISucO-",
        "XgN4fpA0uO8n",
        "_1Eq6TC2wicn",
        "OdGw-l6TEUiP",
        "nfLk6pw2M08a",
        "XXHM8y9kRW5V"
      ],
      "include_colab_link": true,
      "name": "skeleton.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
