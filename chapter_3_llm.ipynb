{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thibaultdouzon/NeuralDocumentClassification/blob/master/chapter_3_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7-WLyF_4_4A"
      },
      "source": [
        "# Setting up LLM connection\n",
        "\n",
        "Let's first setup an OpenAI client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ElM6K7B5Agz"
      },
      "outputs": [],
      "source": [
        "# Install all packages listed in pyproject.toml\n",
        "%pip install click datasets gdown ipython jupyter matplotlib nltk numpy openai pillow polars pydantic requests ruff scikit-learn torch torchmetrics torchvision tqdm transformers==4.45 types-requests types-tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZyhKUwi4_4B"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZX2StsaS4_4B"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "config = json.load(open(\"secrets.json\"))\n",
        "openai_client = openai.AzureOpenAI(**config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoaDazTC4_4C"
      },
      "source": [
        "This should work and respond something like \"The capital of France is Paris.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLgKtVl94_4C"
      },
      "outputs": [],
      "source": [
        "openai_client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
        "    ],\n",
        ").choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39tVm8Ew4_4C"
      },
      "source": [
        "# Imports & Cloning repository\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-i14tYg4_4C"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import io\n",
        "import pickle\n",
        "import sys\n",
        "import tqdm\n",
        "from copy import deepcopy\n",
        "from dataclasses import dataclass\n",
        "from os import path\n",
        "from typing import Callable\n",
        "\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR1jQgVA4_4C"
      },
      "outputs": [],
      "source": [
        "class_names = [\"email\", \"form\", \"handwritten\", \"invoice\", \"advertisement\"]\n",
        "NUM_CLASSES = len(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not path.exists(\"NeuralDocumentClassification\"):\n",
        "    !git clone https://github.com/thibaultdouzon/NeuralDocumentClassification.git\n",
        "else:\n",
        "    !git -C NeuralDocumentClassification pull\n",
        "sys.path.append(\"NeuralDocumentClassification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFAuWnaJ4_4C"
      },
      "outputs": [],
      "source": [
        "from src import download_dataset\n",
        "\n",
        "dataset_path = \"dataset\"\n",
        "download_dataset.download_and_extract(\"all\", dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4Sr8jq_4_4C"
      },
      "outputs": [],
      "source": [
        "with open(path.join(dataset_path, \"train.pkl\"), \"rb\") as f:\n",
        "    train_dataset = pickle.load(f)\n",
        "\n",
        "with open(path.join(dataset_path, \"test.pkl\"), \"rb\") as f:\n",
        "    test_dataset = pickle.load(f)\n",
        "\n",
        "with open(path.join(dataset_path, \"validation.pkl\"), \"rb\") as f:\n",
        "    validation_dataset = pickle.load(f)\n",
        "\n",
        "for split_name, split_dataset in zip(\n",
        "    [\"train\", \"test\", \"validation\"], [train_dataset, test_dataset, validation_dataset]\n",
        "):\n",
        "    print(f\"{split_name}_dataset contains {len(split_dataset)} documents\")\n",
        "train_dataset[0].keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QECwxNk4_4D"
      },
      "source": [
        "Each `dataset` object is a `list` containing multiple document information. A document is a `dict` with the following structure:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"id\": \"Unique document identifier\",\n",
        "  \"image\": \"A PIL.Image object containing the document's image\",\n",
        "  \"label\": \"A number between in [0 .. 4] representing the class of the document\",\n",
        "  \"words\": \"A list of strings (not words !) extracted from the image with an OCR\",\n",
        "  \"boxes\": \"A list of tuples of numbers providing the position of each word in the document\"\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R38D3rMY4_4D"
      },
      "source": [
        "Although API-based LLM can be trained, it turns out tu be very costly. However, thanks to their very extensive training, LLM can understand a natural language description of the task (called prompt) and perform successfully the task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0foKJutD4_4D"
      },
      "source": [
        "Write a function that will only use the text from the document to perform a prediction using OpenAI PT 4o mini\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MNSrArQ4_4D"
      },
      "outputs": [],
      "source": [
        "### Modify the code here ###\n",
        "# See the expected solution by clicking on the cell below\n",
        "\n",
        "\n",
        "def text_prediction(document: dict) -> str:\n",
        "    \"\"\"Process a document and return the predicted class name.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0tJ-xsKn4_4D"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "\n",
        "def text_prediction(document: dict) -> str:\n",
        "    return (\n",
        "        openai_client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": f\"You are a helpful assistant. You are helping a user with a text classification task. Respond with a single word which is the class of the document. Available classes are {class_names}.\",\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"The document contains the following words: {document['words']}\",\n",
        "                },\n",
        "            ],\n",
        "        )\n",
        "        .choices[0]\n",
        "        .message.content\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWMeJfF94_4D"
      },
      "source": [
        "Let's now evaluate our model on the validation test. Make it reusable and take the `prediction_fn` as input.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAcIsbDe4_4D"
      },
      "outputs": [],
      "source": [
        "### Modify the code here ###\n",
        "# See the expected solution by clicking on the cell below\n",
        "\n",
        "\n",
        "def evaluate(\n",
        "    prediction_fn: Callable[[dict], str], dataset: dict\n",
        ") -> tuple[float, list[str], list[str]]:\n",
        "    \"Evalute the prediction function on the dataset and return the accuracy, predictions and targets.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HOK8K3vX4_4D"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "\n",
        "def evaluate(\n",
        "    prediction_fn: Callable[[dict], str], dataset: dict\n",
        ") -> tuple[float, list[str], list[str]]:\n",
        "    \"Evalute the prediction function on the dataset and return the accuracy.\"\n",
        "\n",
        "    predictions = []\n",
        "    accuracies = []\n",
        "    targets = [class_names[document[\"label\"]] for document in dataset]\n",
        "    with tqdm.tqdm(desc=\"Evaluation\", total=len(dataset)) as pbar:\n",
        "        for document, target in zip(dataset, targets):\n",
        "            predictions.append(prediction_fn(document))\n",
        "            accuracies.append(predictions[-1] == target)\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix(metric=f\"{sum(accuracies) / len(accuracies):.2f}\")\n",
        "\n",
        "    return sum(accuracies) / len(accuracies), predictions, targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IkOFaQu4_4D"
      },
      "source": [
        "Let's evaluate GPT-4o-mini on text input and take a look at its predictions. Let's try to build the confusion matrix on the validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FXZ8kXU4_4D"
      },
      "outputs": [],
      "source": [
        "acc, preds, tgts = evaluate(text_prediction, validation_dataset)\n",
        "acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBt9ui6X4_4D"
      },
      "source": [
        "Depending on your prompt and luck, the following code might break, what's the issue?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "preds_idx = [class_names.index(pred) for pred in preds]\n",
        "tgts_idx = [class_names.index(tgt) for tgt in tgts]\n",
        "\n",
        "confusion_matrix(tgts_idx, preds_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5bvfYvZ4_4D"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "# The model can generate anything, including something that is not a class name.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "preds_idx = [\n",
        "    class_names.index(pred) if pred in class_names else len(class_names)\n",
        "    for pred in preds\n",
        "]\n",
        "tgts_idx = [class_names.index(tgt) for tgt in tgts]\n",
        "\n",
        "confusion_matrix(tgts_idx, preds_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q283fidK4_4D"
      },
      "source": [
        "Some LLMs like GPT-4o(-mini) are multimodal. They can process multiple modalities of input and some can also produce different output modalities.\n",
        "\n",
        "GPT-4o-mini can process both text and images for example. Let's write a prediction function providing an image to GPT-4o-mini.\n",
        "\n",
        "Use the OpenAI documentation to figure out how to write the messages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xtRhAf-4_4D"
      },
      "outputs": [],
      "source": [
        "def image_to_b64(image: PIL.Image) -> str:\n",
        "    \"\"\"Convert a PIL image to a base64 string.\"\"\"\n",
        "    io_buf = io.BytesIO()\n",
        "    image.thumbnail((128, 128))\n",
        "    image.save(io_buf, format=\"jpeg\")\n",
        "    return base64.b64encode(io_buf.getvalue()).decode(\"utf-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnR9wn0d4_4E"
      },
      "outputs": [],
      "source": [
        "### Insert your code here ###\n",
        "# See the expected solution by clicking on the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zm52Zksa4_4E"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "\n",
        "def image_prediction(document: dict) -> str:\n",
        "    base64_image = image_to_b64(deepcopy(document[\"image\"]))\n",
        "    return (\n",
        "        openai_client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are a helpful assistant. You are helping a user with a text classification task. \"\n",
        "                    \"Respond with a single word which is the class of the document. Available classes are {class_names}.\",\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": \"This is an image document.\"},\n",
        "                        {\n",
        "                            \"type\": \"image_url\",\n",
        "                            \"image_url\": {\n",
        "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
        "                            },\n",
        "                        },\n",
        "                    ],\n",
        "                },\n",
        "            ],\n",
        "        )\n",
        "        .choices[0]\n",
        "        .message.content\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCFcH3SU4_4E"
      },
      "outputs": [],
      "source": [
        "class_names[train_dataset[0][\"label\"]], image_prediction(train_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "acc, preds, tgts = evaluate(image_prediction, validation_dataset[:100])\n",
        "acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J33YYIYp5Ngu"
      },
      "source": [
        "Do not hesitate to compare the performance of the models created during all the notebooks."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
