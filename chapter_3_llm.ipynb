{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up LLM connection\n",
    "\n",
    "Let's first setup an OpenAI client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "config = json.load(open(\"secrets.json\"))\n",
    "\n",
    "openai_client = openai.AzureOpenAI(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should work and respond something like \"The capital of France is Paris.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    ],\n",
    ").choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Cloning repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import pickle\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from os import path\n",
    "\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"email\", \"form\", \"handwritten\", \"invoice\", \"advertisement\"]\n",
    "NUM_CLASSES = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import download_dataset\n",
    "\n",
    "dataset_path = \"dataset\"\n",
    "\n",
    "download_dataset.download_and_extract(\"all\", dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path.join(dataset_path, \"train.pkl\"), \"rb\") as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "with open(path.join(dataset_path, \"test.pkl\"), \"rb\") as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "with open(path.join(dataset_path, \"validation.pkl\"), \"rb\") as f:\n",
    "    validation_dataset = pickle.load(f)\n",
    "\n",
    "\n",
    "for split_name, split_dataset in zip(\n",
    "    [\"train\", \"test\", \"validation\"], [train_dataset, test_dataset, validation_dataset]\n",
    "):\n",
    "    print(f\"{split_name}_dataset contains {len(split_dataset)} documents\")\n",
    "train_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `dataset` object is a `list` containing multiple document information. A document is a `dict` with the following structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"Unique document identifier\",\n",
    "  \"image\": \"A PIL.Image object containing the document's image\",\n",
    "  \"label\": \"A number between in [0 .. 4] representing the class of the document\",\n",
    "  \"words\": \"A list of strings (not words !) extracted from the image with an OCR\",\n",
    "  \"boxes\": \"A list of tuples of numbers providing the position of each word in the document\"\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although API-based LLM can be trained, it turns out tu be very costly. However, thanks to their very extensive training, LLM can understand a natural language description of the task (called prompt) and perform successfully the task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that will only use the text from the document to perform a prediction using OpenAI PT 4o mini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prediction(document: dict) -> str:\n",
    "    \"\"\"Process a document and return the predicted class name.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "\n",
    "\n",
    "def text_prediction(document: dict) -> str:\n",
    "    return (\n",
    "        openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"You are a helpful assistant. You are helping a user with a text classification task. Respond with a single word which is the class of the document. Available classes are {class_names}.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"The document contains the following words: {document['words']}\",\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        .choices[0]\n",
    "        .message.content\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now evaluate our model on the validation test. Make it reusable and take the `prediction_fn` as input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    prediction_fn: Callable[[dict], str], dataset: dict\n",
    ") -> tuple[float, list[str], list[str]]:\n",
    "    \"Evalute the prediction function on the dataset and return the accuracy, predictions and targets.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    prediction_fn: Callable[[dict], str], dataset: dict\n",
    ") -> tuple[float, list[str], list[str]]:\n",
    "    \"Evalute the prediction function on the dataset and return the accuracy.\"\n",
    "\n",
    "    predictions = []\n",
    "    accuracies = []\n",
    "    targets = [class_names[document[\"label\"]] for document in dataset]\n",
    "    with tqdm.tqdm(desc=\"Evaluation\", total=len(dataset)) as pbar:\n",
    "        for document, target in zip(dataset, targets):\n",
    "            predictions.append(prediction_fn(document))\n",
    "            accuracies.append(predictions[-1] == target)\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix(metric=f\"{sum(accuracies) / len(accuracies):.2f}\")\n",
    "\n",
    "    return sum(accuracies) / len(accuracies), predictions, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate GPT-4o-mini on text input and take a look at its predictions. Let's try to build the confusion matrix on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, preds, tgts = evaluate(text_prediction, validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your prompt and luck, the following code might break, what's the issue?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_idx = [\n",
    "    class_names.index(pred) if pred in class_names else len(class_names)\n",
    "    for pred in preds\n",
    "]\n",
    "tgts_idx = [class_names.index(tgt) for tgt in tgts]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(tgts_idx, preds_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some LLMs like GPT-4o(-mini) are multimodal. They can process multiple modalities of input and some can also produce different output modalities.\n",
    "\n",
    "GPT-4o-mini can process both text and images for example. Let's write a prediction function providing an image to GPT-4o-mini.\n",
    "\n",
    "Use the OpenAI documentation to figure out how to write the messages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_b64(image: PIL.Image) -> str:\n",
    "    \"\"\"Convert a PIL image to a base64 string.\"\"\"\n",
    "    io_buf = io.BytesIO()\n",
    "    image.thumbnail((128, 128))\n",
    "    image.save(io_buf, format=\"jpeg\")\n",
    "    return base64.b64encode(io_buf.getvalue()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "\n",
    "\n",
    "def image_prediction(document: dict) -> str:\n",
    "    base64_image = image_to_b64(deepcopy(document[\"image\"]))\n",
    "    return (\n",
    "        openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant. You are helping a user with a text classification task. \"\n",
    "                    \"Respond with a single word which is the class of the document. Available classes are {class_names}.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"This is an image document.\"},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            },\n",
    "                        },\n",
    "                    ],\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "        .choices[0]\n",
    "        .message.content\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names[train_dataset[0][\"label\"]], image_prediction(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
